{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f730149",
   "metadata": {},
   "source": [
    "## üìù Note\n",
    "\n",
    "This notebook demonstrates the training process interactively. For production use or automated training, consider using the modular Python scripts in the `scripts/` directory:\n",
    "\n",
    "- `scripts/train.py` - Complete training pipeline\n",
    "- `scripts/evaluate.py` - Model evaluation\n",
    "- `scripts/predict.py` - Single image inference\n",
    "\n",
    "The core functionality has been organized into modules in the `src/` directory for better code organization and reusability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22e11b",
   "metadata": {},
   "source": [
    "# Belgian Bird Species Classifier\n",
    "\n",
    "This notebook implements a high-accuracy image classifier for Belgian bird species using PyTorch and transfer learning with EfficientNet. The model is trained on a custom dataset containing approximately 130 images per species, with each image resized to 224√ó224."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ae310",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, we'll import all necessary libraries and set random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Check if running in Colab (skip if running locally)\n",
    "try:\n",
    "    assert EOFError\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab, installing required packages...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"timm\", \"albumentations\", \"huggingface_hub\"])\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    # Install huggingface_hub if not available\n",
    "    try:\n",
    "        import huggingface_hub\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"huggingface_hub\"])\n",
    "\n",
    "# Import dependencies\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "\n",
    "# Safe import of tqdm with fallback\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    # Test if it actually works\n",
    "    tqdm(range(1))\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    print(\"tqdm.notebook not available, falling back to regular tqdm\")\n",
    "    from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2 as transforms_v2\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e7e9f",
   "metadata": {},
   "source": [
    "## 2. Dataset Configuration\n",
    "\n",
    "Define dataset paths and configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724dd0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset download and configuration\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "# Download dataset from Hugging Face\n",
    "print(\"Downloading dataset from Hugging Face...\")\n",
    "LOCAL_DIR = \"../data/\"\n",
    "snapshot_download(\n",
    "    repo_id=\"Ez-Clap/bird-species\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=LOCAL_DIR,\n",
    "    local_dir_use_symlinks=False,\n",
    "    allow_patterns=[\"BelgianSpecies/train/**\", \"BelgianSpecies/test/**\", \"BelgianSpecies/valid/**\", \"BelgianSpecies/validation/**\", \"BelgianSpecies/val/**\"],\n",
    "    revision=\"main\"\n",
    ")\n",
    "\n",
    "# Dataset paths\n",
    "DATA_ROOT = Path(LOCAL_DIR + \"/BelgianSpecies\")\n",
    "TRAIN_DIR = DATA_ROOT / 'train'\n",
    "TEST_DIR = DATA_ROOT / 'test'\n",
    "VALID_DIR = DATA_ROOT / 'valid'\n",
    "\n",
    "# Check which validation directory exists\n",
    "if not VALID_DIR.exists():\n",
    "    if (DATA_ROOT / 'validation').exists():\n",
    "        VALID_DIR = DATA_ROOT / 'validation'\n",
    "    elif (DATA_ROOT / 'val').exists():\n",
    "        VALID_DIR = DATA_ROOT / 'val'\n",
    "\n",
    "print(f\"Dataset downloaded to: {DATA_ROOT}\")\n",
    "print(f\"Train directory: {TRAIN_DIR}\")\n",
    "print(f\"Test directory: {TEST_DIR}\")\n",
    "print(f\"Valid directory: {VALID_DIR}\")\n",
    "\n",
    "# Configuration parameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "IMG_SIZE = 224\n",
    "NUM_EPOCHS_PHASE1 = 10\n",
    "NUM_EPOCHS_PHASE2 = 30\n",
    "LEARNING_RATE_PHASE1 = 1e-3\n",
    "LEARNING_RATE_PHASE2 = 2e-4\n",
    "LABEL_SMOOTHING = 0.1\n",
    "WEIGHT_DECAY = 1e-4\n",
    "# Get class names and number of classes\n",
    "class_names = sorted([d.name for d in TRAIN_DIR.iterdir() if d.is_dir()])\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"Found {NUM_CLASSES} classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f13b5a4",
   "metadata": {},
   "source": [
    "## 3. Custom Dataset and Data Augmentation\n",
    "\n",
    "We'll create a custom dataset class to load images from disk and apply different augmentations to train and validation sets:\n",
    "\n",
    "- **Training augmentations**: \n",
    "  - Horizontal flips\n",
    "  - Random rotations (¬±15¬∞)\n",
    "  - Random resized crops\n",
    "  - Color jitter (brightness, contrast, saturation)\n",
    "  - Random erasing\n",
    "  \n",
    "- **Validation/Test augmentations**:\n",
    "  - Center crop/resize\n",
    "  - Normalization with ImageNet mean and std\n",
    "\n",
    "Using strong augmentation helps improve generalization on small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ae3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet mean and std for normalization\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Define augmentations using albumentations for more efficient and comprehensive transforms\n",
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(size=(IMG_SIZE, IMG_SIZE), scale=(0.7, 1.0)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    A.CoarseDropout(max_holes=1, max_height=32, max_width=32, p=0.2),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE + 32, IMG_SIZE + 32),\n",
    "    A.CenterCrop(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# Custom Dataset class\n",
    "class BirdSpeciesDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "        \n",
    "        # Load all image paths and labels\n",
    "        for class_folder in sorted(self.root_dir.iterdir()):\n",
    "            if class_folder.is_dir():\n",
    "                class_idx = self.class_to_idx[class_folder.name]\n",
    "                for img_path in class_folder.glob('*.jpg'):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(class_idx)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "# Create datasets\n",
    "train_dataset = BirdSpeciesDataset(TRAIN_DIR, transform=train_transform)\n",
    "valid_dataset = BirdSpeciesDataset(VALID_DIR, transform=val_transform)\n",
    "test_dataset = BirdSpeciesDataset(TEST_DIR, transform=val_transform)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d4131",
   "metadata": {},
   "source": [
    "### Visualize Sample Images with Augmentations\n",
    "\n",
    "Let's visualize some samples from our dataset with the applied augmentations to make sure everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2015552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show images\n",
    "def show_samples(dataset, num_samples=4, cols=4):\n",
    "    figure = plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_samples):\n",
    "        image, label = dataset[random.randint(0, len(dataset)-1)]\n",
    "        \n",
    "        if isinstance(image, torch.Tensor):\n",
    "            # Convert tensor to numpy array for display\n",
    "            image = image.numpy().transpose(1, 2, 0)\n",
    "            # Unnormalize the image\n",
    "            image = image * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)\n",
    "            # Clip values to valid range\n",
    "            image = np.clip(image, 0, 1)\n",
    "        \n",
    "        plt.subplot(1, cols, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(class_names[label])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show sample training images with augmentation\n",
    "show_samples(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6605a",
   "metadata": {},
   "source": [
    "## 4. Data Loaders and Cross-Validation Setup\n",
    "\n",
    "We'll implement K-Fold cross-validation to make the most of our small dataset. \n",
    "This ensures all data is used for both training and validation at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# DataLoader function for training and validation splits\n",
    "def get_data_loaders(train_dataset, valid_dataset=None, test_dataset=None, \n",
    "                    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "                    k_fold=5, fold_index=0):\n",
    "    \n",
    "    if valid_dataset is not None:\n",
    "        # If validation set is provided, use standard train/val/test split\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = None\n",
    "        if test_dataset:\n",
    "            test_loader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=True\n",
    "            )\n",
    "        \n",
    "        return train_loader, valid_loader, test_loader, None\n",
    "    \n",
    "    else:\n",
    "        # If no validation set, use K-fold cross-validation\n",
    "        indices = list(range(len(train_dataset)))\n",
    "        kfold = KFold(n_splits=k_fold, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        # Get train/val indices for the current fold\n",
    "        train_folds = []\n",
    "        val_folds = []\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(indices)):\n",
    "            train_folds.append(train_idx)\n",
    "            val_folds.append(val_idx)\n",
    "        \n",
    "        # Use the specified fold\n",
    "        train_idx = train_folds[fold_index]\n",
    "        val_idx = val_folds[fold_index]\n",
    "        \n",
    "        # Create samplers\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=train_sampler,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        valid_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=val_sampler,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Return fold information for potential ensemble later\n",
    "        return train_loader, valid_loader, None, (train_folds, val_folds)\n",
    "\n",
    "# Define k-fold cross-validation parameters\n",
    "K_FOLDS = 5\n",
    "CURRENT_FOLD = 0  # Start with the first fold\n",
    "\n",
    "# Get dataloaders\n",
    "train_loader, val_loader, test_loader, fold_info = get_data_loaders(\n",
    "    train_dataset, valid_dataset, test_dataset, \n",
    "    k_fold=K_FOLDS, fold_index=CURRENT_FOLD\n",
    ")\n",
    "\n",
    "print(f\"Number of batches in train loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in validation loader: {len(val_loader)}\")\n",
    "if test_loader:\n",
    "    print(f\"Number of batches in test loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132ec19",
   "metadata": {},
   "source": [
    "## 5. Model Architecture\n",
    "\n",
    "We'll use EfficientNet-B3 from the `timm` library with pre-trained weights from ImageNet. The classifier head will be replaced with a new linear layer matching our number of bird species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, model_name=\"efficientnet_b3\", pretrained=True):\n",
    "    # Create a model with pretrained weights\n",
    "    model = timm.create_model(model_name, pretrained=pretrained)\n",
    "    \n",
    "    # Replace classifier head\n",
    "    if 'efficientnet' in model_name:\n",
    "        in_features = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(in_features, num_classes)\n",
    "    else:\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model and move to device\n",
    "model = create_model(NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db59db",
   "metadata": {},
   "source": [
    "## 6. Training Functions\n",
    "\n",
    "Now we'll define training and validation functions, including:\n",
    "- Loss function with label smoothing (which helps prevent overfitting)\n",
    "- Optimizers (AdamW for better weight decay handling)\n",
    "- Learning rate schedulers\n",
    "- Early stopping\n",
    "- Model checkpoint saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41dc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function with label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Use tqdm for progress tracking with a simple fallback mechanism\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\")\n",
    "    for batch_idx, (inputs, targets) in progress_bar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{running_loss / (batch_idx + 1):.4f}\",\n",
    "            'acc': f\"{100. * correct / total:.2f}%\"\n",
    "        })\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "# Validation function\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Validation\")\n",
    "        for batch_idx, (inputs, targets) in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Store predictions and targets for later analysis\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{running_loss / (batch_idx + 1):.4f}\",\n",
    "                'acc': f\"{100. * correct / total:.2f}%\"\n",
    "            })\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total, all_preds, all_targets\n",
    "\n",
    "# Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            return True\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            if current_score < self.best_score - self.min_delta:\n",
    "                self.best_score = current_score\n",
    "                self.counter = 0\n",
    "                return True\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        else:  # mode == 'max'\n",
    "            if current_score > self.best_score + self.min_delta:\n",
    "                self.best_score = current_score\n",
    "                self.counter = 0\n",
    "                return True\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77440a",
   "metadata": {},
   "source": [
    "## 7. Phase 1: Training the Classifier Head\n",
    "\n",
    "In this phase, we'll freeze the backbone of the model (EfficientNet) and only train the classifier head. This allows us to rapidly adapt the pre-trained model to our specific bird species classification task without disturbing the feature extraction capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Train only the classifier head\n",
    "def train_phase1(model, train_loader, val_loader, num_epochs=NUM_EPOCHS_PHASE1):\n",
    "    # Freeze all layers except the classifier\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Unfreeze the classifier\n",
    "    if hasattr(model, 'classifier'):\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Print trainable parameters\n",
    "    print(\"Trainable parameters in Phase 1:\")\n",
    "    trainable_params = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "    print(trainable_params)\n",
    "    \n",
    "    # Define optimizer and scheduler\n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                           lr=LEARNING_RATE_PHASE1, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, mode='max')\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Check if we should save the model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'../models/best_model_phase1_fold{CURRENT_FOLD}.pt')\n",
    "            print(f\"Saved best model with accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Check early stopping\n",
    "        if early_stopping(val_acc) and early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(f'../models/best_model_phase1_fold{CURRENT_FOLD}.pt'))\n",
    "    return model, history\n",
    "\n",
    "# Train Phase 1\n",
    "print(\"Starting Phase 1 Training: Classifier head only\")\n",
    "model, history_phase1 = train_phase1(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f662068",
   "metadata": {},
   "source": [
    "### Visualize Phase 1 Training Results\n",
    "\n",
    "Let's plot the training and validation loss and accuracy to see how our model is performing during Phase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, title=\"Training History\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    ax1.plot(history['train_loss'], label='Train Loss')\n",
    "    ax1.plot(history['val_loss'], label='Val Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Loss Curve')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax2.plot(history['train_acc'], label='Train Accuracy')\n",
    "    ax2.plot(history['val_acc'], label='Val Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title('Accuracy Curve')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot Phase 1 training history\n",
    "plot_training_history(history_phase1, \"Phase 1 Training: Classifier Head Only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c14a73f",
   "metadata": {},
   "source": [
    "## 8. Phase 2: Fine-tuning the Model\n",
    "\n",
    "In this phase, we'll unfreeze more layers of the model and train with a lower learning rate. This fine-tuning process allows the pre-trained features to be adjusted to better suit our bird species dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33675b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Fine-tune the model\n",
    "def train_phase2(model, train_loader, val_loader, num_epochs=NUM_EPOCHS_PHASE2):\n",
    "    # Unfreeze layers for fine-tuning\n",
    "    # For EfficientNet, we'll unfreeze the last set of blocks\n",
    "    unfreeze_layers = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'blocks.6' in name or 'blocks.5' in name or 'classifier' in name or 'fc' in name:\n",
    "            param.requires_grad = True\n",
    "            unfreeze_layers.append(name)\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    print(f\"Unfreezing {len(unfreeze_layers)} parameters for fine-tuning\")\n",
    "    \n",
    "    # Define optimizer and scheduler\n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                           lr=LEARNING_RATE_PHASE2, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=7, mode='max')\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        print(f\"Learning rate: {optimizer.param_groups[0]['lr']:.7f}\")\n",
    "        \n",
    "        # Check if we should save the model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'../models/best_model_phase2_fold{CURRENT_FOLD}.pt')\n",
    "            print(f\"Saved best model with accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Check early stopping\n",
    "        if early_stopping(val_acc) and early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(f'../models/best_model_phase2_fold{CURRENT_FOLD}.pt'))\n",
    "    return model, history\n",
    "\n",
    "# Train Phase 2\n",
    "print(\"Starting Phase 2 Training: Fine-tuning\")\n",
    "model, history_phase2 = train_phase2(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda3ee7",
   "metadata": {},
   "source": [
    "### Visualize Phase 2 Training Results\n",
    "\n",
    "Let's plot the training and validation loss and accuracy to see how our model is performing during Phase 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21220816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Phase 2 training history with improved formatting for publication\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "# Plot loss with improved colors\n",
    "ax1.plot(history_phase2['train_loss'], color='#1f77b4', linewidth=2, marker='o', markersize=4, label='Train Loss')\n",
    "ax1.plot(history_phase2['val_loss'], color='#ff7f0e', linewidth=2, marker='s', markersize=4, label='Val Loss')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Loss Curve', fontsize=14)\n",
    "ax1.legend(frameon=False)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# Plot accuracy with improved colors\n",
    "ax2.plot(history_phase2['train_acc'], color='#2ca02c', linewidth=2, marker='o', markersize=4, label='Train Accuracy')\n",
    "ax2.plot(history_phase2['val_acc'], color='#d62728', linewidth=2, marker='s', markersize=4, label='Val Accuracy')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Accuracy Curve', fontsize=14)\n",
    "ax2.legend(frameon=False)\n",
    "ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "# Make axes square\n",
    "ax1.set_box_aspect(1)\n",
    "ax2.set_box_aspect(1)\n",
    "\n",
    "# Save figure to PDF without borders\n",
    "plt.savefig('../results/phase2_training_history.pdf', format='pdf', bbox_inches='tight', \n",
    "            pad_inches=0, dpi=300, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdceaa3f",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation\n",
    "\n",
    "Now we'll evaluate our model in detail, including:\n",
    "- Confusion matrix\n",
    "- Per-class accuracy\n",
    "- Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "    print(f\"Overall Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1) * 100\n",
    "    for i, acc in enumerate(per_class_acc):\n",
    "        print(f\"Class {class_names[i]}: {acc:.2f}%\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_targets, all_preds, target_names=class_names))\n",
    "    \n",
    "    return all_preds, all_targets, cm\n",
    "\n",
    "# Use test set if available, otherwise use validation set\n",
    "eval_loader = test_loader if test_loader else val_loader\n",
    "print(\"Evaluating final model...\")\n",
    "all_preds, all_targets, cm = evaluate_model(model, eval_loader, device)\n",
    "\n",
    "# Calculate dynamic figure size based on number of classes\n",
    "fig_size = max(12, len(class_names) * 0.6)\n",
    "\n",
    "# Plot confusion matrix with improved formatting for publication\n",
    "plt.figure(figsize=(fig_size, fig_size))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'shrink': 0.8}, annot_kws={'size': 8})\n",
    "plt.xlabel('Predicted', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=14, fontweight='bold')\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Improve text formatting to prevent overlapping\n",
    "plt.xticks(rotation=45, ha='right', fontsize=9)\n",
    "plt.yticks(rotation=0, ha='right', fontsize=9)\n",
    "\n",
    "# Remove spines for cleaner look\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save confusion matrix to PDF without borders\n",
    "plt.savefig('../results/confusion_matrix.pdf', format='pdf', bbox_inches='tight', \n",
    "            pad_inches=0.1, dpi=300, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a973c",
   "metadata": {},
   "source": [
    "## 10. Test-Time Augmentation (TTA)\n",
    "\n",
    "Test-time augmentation is a technique where we apply multiple augmentations to a test image and average the predictions. This can lead to more robust predictions, especially for challenging images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb49244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_augmentation(model, image_tensor, device, num_augmentations=10):\n",
    "    \"\"\"Apply multiple augmentations to a single image and average predictions\"\"\"\n",
    "    model.eval()\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)  # Add batch dimension\n",
    "    \n",
    "    # Original prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "    \n",
    "    # Horizontal flip\n",
    "    flipped = torch.flip(image_tensor, [3])  # Flip along width dimension\n",
    "    with torch.no_grad():\n",
    "        flip_outputs = model(flipped)\n",
    "        flip_probabilities = torch.softmax(flip_outputs, dim=1)\n",
    "    \n",
    "    # Average the predictions\n",
    "    avg_probabilities = (probabilities + flip_probabilities) / 2\n",
    "    \n",
    "    # Get top prediction\n",
    "    _, predicted_class = torch.max(avg_probabilities, 1)\n",
    "    \n",
    "    return predicted_class.item(), avg_probabilities.cpu().numpy()[0]\n",
    "\n",
    "# Test TTA on a few random samples\n",
    "def test_tta_on_samples(model, dataloader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    # Get random samples\n",
    "    images, labels = [], []\n",
    "    for _ in range(num_samples):\n",
    "        idx = random.randint(0, len(dataloader.dataset) - 1)\n",
    "        img, label = dataloader.dataset[idx]\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "    \n",
    "    for i, (image, true_label) in enumerate(zip(images, labels)):\n",
    "        # Regular prediction\n",
    "        image_tensor = image.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted_class = torch.max(probabilities, 1)\n",
    "        \n",
    "        # TTA prediction\n",
    "        tta_class, tta_probs = test_time_augmentation(model, image, device)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"True class: {class_names[true_label]}\")\n",
    "        print(f\"Regular prediction: {class_names[predicted_class.item()]} \"\n",
    "              f\"(confidence: {probabilities[0][predicted_class].item():.4f})\")\n",
    "        print(f\"TTA prediction: {class_names[tta_class]} \"\n",
    "              f\"(confidence: {tta_probs[tta_class]:.4f})\")\n",
    "        \n",
    "        # Display image\n",
    "        img_display = image.numpy().transpose(1, 2, 0)\n",
    "        img_display = img_display * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "        \n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(img_display)\n",
    "        plt.title(f\"True: {class_names[true_label]}\\nPred: {class_names[tta_class]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Test TTA on some random samples\n",
    "test_tta_on_samples(model, eval_loader, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2638216c",
   "metadata": {},
   "source": [
    "## 11. K-Fold Cross-Validation (Optional)\n",
    "\n",
    "If we want to maximize our model performance, we can train the model on all K folds and ensemble the predictions. This section demonstrates how to implement k-fold cross-validation for training and model ensembling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kfold_models(k_folds=K_FOLDS, train_dataset=train_dataset):\n",
    "    \"\"\"Train models on multiple folds and save them\"\"\"\n",
    "    models = []\n",
    "    \n",
    "    for fold in range(k_folds):\n",
    "        print(f\"\\n{'='*20}\\nTraining Fold {fold+1}/{k_folds}\\n{'='*20}\")\n",
    "        \n",
    "        # Get data loaders for this fold\n",
    "        train_loader, val_loader, _, _ = get_data_loaders(\n",
    "            train_dataset, k_fold=k_folds, fold_index=fold\n",
    "        )\n",
    "        \n",
    "        # Create and train model\n",
    "        model = create_model(NUM_CLASSES).to(device)\n",
    "        \n",
    "        # Phase 1: Train classifier head\n",
    "        print(\"Phase 1: Training classifier head...\")\n",
    "        model, _ = train_phase1(model, train_loader, val_loader, num_epochs=NUM_EPOCHS_PHASE1)\n",
    "        \n",
    "        # Phase 2: Fine-tune\n",
    "        print(\"Phase 2: Fine-tuning...\")\n",
    "        model, _ = train_phase2(model, train_loader, val_loader, num_epochs=NUM_EPOCHS_PHASE2)\n",
    "        \n",
    "        # Save final model\n",
    "        torch.save(model.state_dict(), f'final_model_fold{fold}.pt')\n",
    "        models.append(model)\n",
    "        \n",
    "    return models\n",
    "\n",
    "def ensemble_prediction(models, image_tensor, device):\n",
    "    \"\"\"Ensemble predictions from multiple models\"\"\"\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    all_probabilities = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            all_probabilities.append(probabilities)\n",
    "    \n",
    "    # Average probabilities\n",
    "    avg_probabilities = torch.mean(torch.stack(all_probabilities), dim=0)\n",
    "    _, predicted_class = torch.max(avg_probabilities, 1)\n",
    "    \n",
    "    return predicted_class.item(), avg_probabilities.cpu().numpy()[0]\n",
    "\n",
    "# Note: Uncomment the following code to train models on all folds\n",
    "# This can take a long time to run!\n",
    "\n",
    "# print(\"Starting k-fold cross-validation training...\")\n",
    "# fold_models = train_kfold_models(k_folds=K_FOLDS)\n",
    "# print(\"Completed training all folds!\")\n",
    "\n",
    "# # Test ensemble prediction on a random image\n",
    "# idx = random.randint(0, len(eval_loader.dataset) - 1)\n",
    "# img, label = eval_loader.dataset[idx]\n",
    "# \n",
    "# ensemble_class, ensemble_probs = ensemble_prediction(fold_models, img, device)\n",
    "# print(f\"\\nEnsemble Prediction Test:\")\n",
    "# print(f\"True class: {class_names[label]}\")\n",
    "# print(f\"Ensemble prediction: {class_names[ensemble_class]}\")\n",
    "# print(f\"Top probabilities: {sorted(zip(class_names, ensemble_probs), key=lambda x: x[1], reverse=True)[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0f1e4",
   "metadata": {},
   "source": [
    "## 12. Model Export and Inference Demo\n",
    "\n",
    "Finally, let's export our best model and demonstrate how to use it for inference on new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ca24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model architecture and weights in a format that can be easily loaded\n",
    "def export_model(model, filename='../models/bird_species_classifier.pt'):\n",
    "    # Save model info\n",
    "    model_info = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'class_names': class_names,\n",
    "        'model_name': 'efficientnet_b3',\n",
    "        'img_size': IMG_SIZE,\n",
    "        'mean': IMAGENET_MEAN,\n",
    "        'std': IMAGENET_STD\n",
    "    }\n",
    "    torch.save(model_info, filename)\n",
    "    print(f\"Model exported to {filename}\")\n",
    "\n",
    "# Export the trained model\n",
    "export_model(model)\n",
    "\n",
    "# Function to load model and make predictions\n",
    "def load_model_and_predict(image_path, model_path='../models/bird_species_classifier.pt'):\n",
    "    # Load model info\n",
    "    model_info = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(len(model_info['class_names']), model_name=model_info['model_name'])\n",
    "    model.load_state_dict(model_info['state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = A.Compose([\n",
    "        A.Resize(model_info['img_size'], model_info['img_size']),\n",
    "        A.Normalize(mean=model_info['mean'], std=model_info['std']),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    img_tensor = transform(image=np.array(img))['image']\n",
    "    \n",
    "    # Apply TTA for better prediction\n",
    "    class_idx, probs = test_time_augmentation(model, img_tensor, device)\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_indices = np.argsort(probs)[-3:][::-1]\n",
    "    top_classes = [model_info['class_names'][i] for i in top_indices]\n",
    "    top_probs = [probs[i] for i in top_indices]\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Input Image\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    bars = plt.barh([1, 2, 3], top_probs, color='skyblue')\n",
    "    plt.yticks([1, 2, 3], top_classes)\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.title(\"Top 3 Predictions\")\n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                 f\"{top_probs[i]:.2f}\", va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return top_classes[0], top_probs[0]\n",
    "\n",
    "# Example of prediction (uncomment to use on a specific image)\n",
    "# Replace 'path_to_test_image.jpg' with the path to your test image\n",
    "predicted_class, confidence = load_model_and_predict('../data/test_bird.png')\n",
    "print(f\"Predicted bird species: {predicted_class} with confidence {confidence:.2f}\")\n",
    "predicted_class, confidence = load_model_and_predict('../data/test_bird_cropped.jpg')\n",
    "print(f\"Predicted bird species: {predicted_class} with confidence {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637248c",
   "metadata": {},
   "source": [
    "## 13. Conclusion\n",
    "\n",
    "In this notebook, we've built a high-accuracy bird species classifier using:\n",
    "\n",
    "1. A custom dataset with strong data augmentation\n",
    "2. Transfer learning with EfficientNet-B3 pre-trained on ImageNet\n",
    "3. Two-phase training (classifier head followed by fine-tuning)\n",
    "4. Techniques like label smoothing, early stopping, and learning rate scheduling\n",
    "5. Test-time augmentation for better prediction accuracy\n",
    "\n",
    "To further improve the model, consider:\n",
    "- Experimenting with different pre-trained models\n",
    "- Trying more augmentation techniques\n",
    "- Using K-fold cross-validation and model ensembling\n",
    "- Collecting more training data if possible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "313BIRDS (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
